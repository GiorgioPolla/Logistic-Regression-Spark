{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centralised Logistic Regression - Giorgio Polla\n",
    "\n",
    "Logistic Regression Classifier implementation.   \n",
    "Centralised version, without cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    read_data = pd.read_csv(filename, header=None)\n",
    "    return read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9   ...    48  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "\n",
       "      49   50     51     52     53     54   55    56  57  \n",
       "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_file(\"../data/spam.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(df):\n",
    "    return df.iloc[:, 0:-1].values\n",
    "\n",
    "def get_y(df):\n",
    "    return df.iloc[:, -1].values\n",
    "\n",
    "def standardize(df):\n",
    "    x = get_x(df)\n",
    "    df_y = df.iloc[:, -1]\n",
    "    \n",
    "    standard_scaler = preprocessing.StandardScaler()\n",
    "    x_scaled = standard_scaler.fit_transform(x)\n",
    "    \n",
    "    df_x = pd.DataFrame(x_scaled)\n",
    "    df_scaled = df_x.join(df_y)\n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00872413388250128"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = standardize(df)\n",
    "df[56][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def predict_probability(x, b, w):\n",
    "    z = np.dot(x, w) + b\n",
    "    return sigmoid(z)\n",
    "\n",
    "def loss(p, y, w, lambda_reg):\n",
    "    epsilon = 1e-10\n",
    "    \n",
    "    error_loss = -np.average(\n",
    "        y * np.log(p + epsilon) + (1 - y) * np.log(1 - p + epsilon)\n",
    "    )\n",
    "    reg_loss = lambda_reg * np.sum(np.square(w)) / (2 * y.size)\n",
    "    \n",
    "    return error_loss + reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df, iterations=20, learning_rate=1, lambda_reg=1):\n",
    "    x = get_x(df)\n",
    "    y = get_y(df)\n",
    "    \n",
    "    b = 0\n",
    "    w = np.zeros(x.shape[1])\n",
    "    \n",
    "    loss_history = [[],[]]\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        pred = predict_probability(x, b, w)\n",
    "        loss_a = loss(pred, y, w, lambda_reg)\n",
    "        \n",
    "        gradient_w = np.dot(x.T, (pred - y))\n",
    "        gradient_b = np.average(pred - y)\n",
    "        regularization = lambda_reg * w\n",
    "        \n",
    "        b -= learning_rate * gradient_b\n",
    "        w -= learning_rate * (gradient_w + regularization) / y.size\n",
    "            \n",
    "        if it % (iterations / 5) == 0:\n",
    "            print(\"It. %4d\\t|\\tLoss: %0.4f\" %  (it, loss_a))\n",
    "        \n",
    "        if it % 10 == 0 or it == iterations - 1:\n",
    "            temp_loss = loss_a\n",
    "            loss_history[0].append(temp_loss)\n",
    "            loss_history[1].append(it)\n",
    "        \n",
    "    return b, w, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, b, w, threshold=0.5):\n",
    "    prob = predict_probability(x, b, w)\n",
    "    return prob >= threshold\n",
    "\n",
    "def accuracy(df, b, w, threshold=0.5):\n",
    "    x = get_x(df)\n",
    "    y = get_y(df)\n",
    "    pred = predict(x, b, w, threshold=threshold)\n",
    "    \n",
    "    accuracy = np.average(pred == y)\n",
    "    print(\"Accuracy: %0.4f\" % accuracy)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It.    0\t|\tLoss: 0.6931\n",
      "It.   20\t|\tLoss: 0.2189\n",
      "It.   40\t|\tLoss: 0.2148\n",
      "It.   60\t|\tLoss: 0.2132\n",
      "It.   80\t|\tLoss: 0.2124\n",
      "Accuracy: 0.9272\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b, w, loss_history = train(df, \n",
    "                           iterations=100, \n",
    "                           learning_rate=10, \n",
    "                           lambda_reg=1\n",
    "                          )\n",
    "\n",
    "plt.plot(np.asarray(loss_history[1]), np.asarray(loss_history[0]))\n",
    "\n",
    "accuracy(df, b, w, threshold=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Accuracy sklearn: 0.9302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x = get_x(df)\n",
    "y = get_y(df)\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    verbose=1, \n",
    "    max_iter=9, \n",
    "    solver='liblinear'\n",
    ")\n",
    "lr_model.fit(x, y)\n",
    "\n",
    "print('Accuracy sklearn: {:.4f}'.format(lr_model.score(x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
