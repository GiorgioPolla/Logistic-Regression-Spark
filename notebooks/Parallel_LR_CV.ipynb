{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Logistic Regression Classifier on Spark\n",
    "\n",
    "Author: **Giorgio Polla**  \n",
    "Date: **TODO/11/2019**  \n",
    "\n",
    "Implementation of a Logistic Regression classifier on Spark, with Python.  \n",
    "The algorithm is tested using cross-validation on the _Spam_ dataset available at https://web.stanford.edu/~hastie/ElemStatLearn/data.html.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and constants\n",
    "\n",
    "Import of the following libraries:  \n",
    "* `pyspark` to utilize *Spark*;  \n",
    "* `time` to track the time performance of the implementation;  \n",
    "* `numpy` to easily operate with number arrays;  \n",
    "* `random` to provide the random functionalities used in the cross-validation dataset split;  \n",
    "* `matplotlib` to plot graphs;  \n",
    "* `sklearn` to easily compute some evaluation metrics.  \n",
    "\n",
    "Moreover, some operative constants used in the following are defined, and finally the Spark context is intialised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randrange\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "FILE_PATH = '../data/spam.txt'\n",
    "N_WORKERS = 8\n",
    "EPSILON = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File reading\n",
    "The spam dataset is loaded as an RDD, using the `textFile()` function.  \n",
    "The RDD is then manipulated in order to have each record as a tuple **(X, y)** , where:  \n",
    "**X** is an array containing the features of the example (57 float numbers);  \n",
    "**y** is an integer containing the label of the example (0 or 1).  \n",
    "\n",
    "The result is then quickly tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    rdd = sc.textFile(file_path)\n",
    "    \n",
    "    rdd = rdd.map(\n",
    "        lambda x: (\n",
    "            [float(el) for el in x[:-1].split()],\n",
    "            int(x[-1])\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = read_file(FILE_PATH)\n",
    "rdd.take(1)[0][0][56] # test -> 278.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation\n",
    "Each row of the RDD is standardised; this is done by first obtaining the mean for each column, then obtaining the standard deviation for them, and finally applying the standardisation formula.  \n",
    "\n",
    "The result is then again quickly tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise(rdd):    \n",
    "    n_rows = rdd.count()\n",
    "    col_sum = rdd.map(\n",
    "        lambda x:\n",
    "            x[0]\n",
    "    ).reduce(\n",
    "        lambda x, y:\n",
    "            [sum(el) for el in zip(x, y)]\n",
    "    )\n",
    "    mean = np.divide(col_sum, n_rows)\n",
    "    \n",
    "    variance = rdd.map(\n",
    "        lambda x: np.square(x[0] - mean)\n",
    "    ).reduce(\n",
    "        lambda x, y:\n",
    "            [sum(el) for el in zip(x, y)]\n",
    "    )\n",
    "    std_dev = np.sqrt(np.divide(variance, n_rows))\n",
    "    \n",
    "    rdd = rdd.map(\n",
    "        lambda x: (\n",
    "            np.divide((x[0] - mean), std_dev),\n",
    "            x[1]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00872413388250125"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = standardise(rdd)\n",
    "rdd.take(1)[0][0][56] # test -> -0.008724"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "The training phase follows the typical Logistc Regression fashion, with some adjustments to exploit the Spark parallelisation.  \n",
    "It is worth noting that the notation is consistent, and in particular:  \n",
    "* **rdd** is an RDD containing the records on which to train the model;\n",
    "* **x** is a data point feature array (57 float numbers);  \n",
    "* **y** is a data point label (integer, either 0 or 1);  \n",
    "* **b** is the regression bias term (float number);  \n",
    "* **w** is the regression weights array (57 float numbers);  \n",
    "* **p** is the predicted class probability for of data point (float number between 0 and 1);\n",
    "\n",
    "In the first section there are the support functions for the proper training phase.  \n",
    "* `sigmoid()` simply represents the Sigmoid function;  \n",
    "* `predict_probability()` calculates and returns the predicted class probability **y** for each record, exploting the `sigmoid()` function;  \n",
    "* `cross_entropy()` is the Cross Entropy function, utilised to obtain the training error of the model;  \n",
    "* `gradient()` calculates the gradient for the bias term (**gradient_b**),  the gradient for the weights, in a single array (**gradient_w**), and the sum of the cross entropy error for each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def predict_probability(x, b, w):\n",
    "    z = np.dot(x, w) + b\n",
    "    return sigmoid(z)\n",
    "\n",
    "\n",
    "def cross_entropy(p, y):    \n",
    "    if y == 1:\n",
    "        error_loss = -np.log(p + EPSILON)\n",
    "    else:\n",
    "        error_loss = -np.log(1 - p + EPSILON)\n",
    "    \n",
    "    return error_loss\n",
    "\n",
    "\n",
    "def gradient(rdd, b, w):\n",
    "    gradient_b, gradient_w, error_loss = rdd.map(\n",
    "        lambda x: (\n",
    "            x[0],\n",
    "            x[1],\n",
    "            predict_probability(x[0], b, w),\n",
    "        )\n",
    "    ).map(\n",
    "        lambda x: (\n",
    "            x[2] - x[1],\n",
    "            np.multiply(\n",
    "                x[2] - x[1],\n",
    "                x[0]\n",
    "            ),\n",
    "            cross_entropy(\n",
    "                x[2],\n",
    "                x[1]\n",
    "            )\n",
    "        )\n",
    "    ).reduce(\n",
    "        lambda x, y: (\n",
    "            x[0] + y[0],\n",
    "            [sum(el) for el in zip(x[1], y[1])],\n",
    "            x[2] + y[2]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return gradient_b, gradient_w, error_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train function considerds the additional parameters:  \n",
    "* **iterations**, the number of iterations to repeat in the training phase;\n",
    "* **learning_rate**, the learing rate in the training phase;\n",
    "* **lambda_reg**, the regularization parameter lambda, used to control the Ridge-like regularization adopted;\n",
    "* **verbose**, controlling whether or not to stamp additional information.  \n",
    "\n",
    "The training phase proceeds inside the main iteration loop by calculating each time the gradient for the bias **b** and the weights **w**, applying the gradient descent technique with appropriate regularization, and recording the total loss (cross-entropy loss **err_loss** plus regularization loss **reg_loss**).  \n",
    "At the end of the training phase the function returns the trained bias and weights, as well as the array **loss_history** containing the records of the total loss during the whole process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rdd, iterations=None, learning_rate=None, \n",
    "          lambda_reg=None, verbose=None):\n",
    "    n_rows = rdd.count()\n",
    "    n_features = len(rdd.first()[0])\n",
    "    b = 0\n",
    "    w = np.zeros(n_features)\n",
    "    \n",
    "    if iterations == None:\n",
    "        iterations = 10\n",
    "    if learning_rate == None:\n",
    "        learning_rate = 10\n",
    "    if lambda_reg == None:\n",
    "        lambda_reg = 1\n",
    "    if verbose == None:\n",
    "        verbose = True\n",
    "    \n",
    "    loss_history = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        gradient_b, gradient_w, err_loss = gradient(rdd, b, w)\n",
    "        \n",
    "        reg_loss = lambda_reg * np.sum(np.square(w)) / 2\n",
    "        regularization = lambda_reg * w\n",
    "        \n",
    "        b -= learning_rate * gradient_b / n_rows\n",
    "        w -= learning_rate * (gradient_w + regularization) / n_rows\n",
    "        \n",
    "        total_loss = (err_loss + reg_loss) / n_rows\n",
    "        loss_history.append(total_loss)\n",
    "        \n",
    "        if verbose and it % (iterations / 5) == 0:\n",
    "            print(\"It. %4d\\t|\\tLoss: %0.4f\\t|\\tTime: %0.2f s\" %  \n",
    "                  (it, total_loss, (time.time() - start_time)))\n",
    "    if verbose:\n",
    "        total_time = time.time() - start_time\n",
    "        print('\\nTotal time: %0.2f s\\nIters frequency: %0.2f Hz' % \n",
    "              (total_time, iterations / total_time))\n",
    "    \n",
    "    return b, w, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation\n",
    "The evaluation is entirely managed by the follwing two functions, following the usual parameter naming conventions.  \n",
    "* `classify()` is a support function that returns wether a data point has been classified as a _True Positve_ (**tp**), a _True Negative_ (**tn**), a _False Negative_ (**fn**) or a _False Positve_ (**fp**);  \n",
    "* `evaluate()` computes the traditional evaluation metric for classification, and in particular the **Accuracy**, **Precision**, **Recall**, **Specificity**, **F1-Score**, final **Cost Error**, area under the ROC curve (**AUC**) and precision-recall score (**P-R Score**), and returns them packed in a dictionary. If the parameter **plot** is positively flagged, the two plots of the ROC and precision-recall curves are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(p, y, threshold=0.5):\n",
    "    if (p >= threshold) == y:\n",
    "        return 'tp' if y==1 else 'tn'\n",
    "    else:\n",
    "        return 'fn' if y==1 else 'fp'\n",
    "            \n",
    "        \n",
    "def evaluate(rdd, b, w, loss_history=[None], plot=True):\n",
    "    \n",
    "    rdd_pred = rdd.map(\n",
    "        lambda x: (\n",
    "            predict_probability(x[0], b, w),\n",
    "            x[1]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    predictions = rdd_pred.map(\n",
    "        lambda x:\n",
    "            x[0]\n",
    "    ).collect()\n",
    "    \n",
    "    corrects = rdd_pred.map(\n",
    "        lambda x:\n",
    "            x[1]\n",
    "    ).collect()\n",
    "    \n",
    "    c_m = rdd_pred.map(\n",
    "        lambda x: (\n",
    "            classify(x[0], x[1]),\n",
    "            1\n",
    "        )\n",
    "    ).reduceByKey(\n",
    "        lambda x, y:\n",
    "            x+y\n",
    "    )\n",
    "    c_m = dict(c_m.collect())\n",
    "    \n",
    "    roc1, roc2, _ = roc_curve(corrects, predictions)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    results['Confusion Matrix'] = c_m\n",
    "    \n",
    "    results['Accuracy'] = (c_m['tp'] + c_m['tn']) \\\n",
    "        / (c_m['tp'] + c_m['tn'] + c_m['fp'] + c_m['fn'])\n",
    "    \n",
    "    results['Precision'] = c_m['tp'] / (c_m['tp'] + c_m['fp'])\n",
    "    \n",
    "    results['Recall'] = c_m['tp'] / (c_m['tp'] + c_m['fn'])\n",
    "    \n",
    "    results['Specificity'] = c_m['tn'] / (c_m['tn'] + c_m['fp'])\n",
    "    \n",
    "    results['F1-Score'] = 2 * results['Precision'] * results['Recall'] \\\n",
    "        / (results['Precision'] + results['Recall'])\n",
    "    \n",
    "    results['Cost Error'] = loss_history[-1]\n",
    "    \n",
    "    results['AUC'] = auc(roc1, roc2)\n",
    "    \n",
    "    results['PR-Score'] = average_precision_score(corrects, predictions)\n",
    "    \n",
    "    if plot:\n",
    "        plt.title('ROC Curve')\n",
    "        plt.plot(roc1, roc2, color='darkorange', \n",
    "                 label='ROC curve (area %0.2f)' % results['AUC'])\n",
    "        plt.plot([0, 1], [0, 1], color='navy', linestyle = '--')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.show()\n",
    "\n",
    "        pr1, pr2, _ = precision_recall_curve(corrects, predictions)\n",
    "\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.step(pr2, pr1, color='black', alpha=0.2,\n",
    "                 label='PR curve (area %0.2f)' % results['PR-Score'])\n",
    "        plt.fill_between(pr2, pr1, alpha=0.2, color='black')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.show()\n",
    "    \n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "The traditional cross-validation technique is here implemented, with some tweakings to exploit the Spark parallelisation.  \n",
    "* `transform_c_v()` transforms the RDD to allow the cross-validation split: each record is randomly assigned to one fold (which range depends on the **folds** number chosen) by adding a label assigned by the `randrange()` functions;  \n",
    "* `get_block_data()` takes the original train RDD and splits it in **rdd_train** and **rdd_test** according to the labels of each element and the training fold extracted **fold_train**;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_c_v(rdd, folds):\n",
    "    random.seed()\n",
    "    rdd_cv = rdd.map(\n",
    "        lambda x: (\n",
    "            x[0],\n",
    "            x[1],\n",
    "            randrange(folds)\n",
    "        )\n",
    "    )\n",
    "    return rdd_cv\n",
    "\n",
    "\n",
    "def get_block_data(rdd, fold_train):\n",
    "    rdd_train = rdd.filter(\n",
    "        lambda x:\n",
    "            x[2] != fold_train\n",
    "    ).map(\n",
    "        lambda x: (\n",
    "            x[0],\n",
    "            x[1]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    rdd_test = rdd.filter(\n",
    "        lambda x:\n",
    "            x[2] == fold_train\n",
    "    ).map(\n",
    "        lambda x: (\n",
    "            x[0],\n",
    "            x[1]\n",
    "        )\n",
    "    )\n",
    "    return rdd_train, rdd_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proper cross-validation process is here executed: given an RDD and a number of folds **folds** in which to split the dataset (and the usual `train()` parameters, to pass to that function when called), it iterates the training and testing phases selecting each time the proper **rdd_test** and **rdd_train** split, according to the appropriate training fold **fold** selected.  \n",
    "\n",
    "The accuracy of the trained model (obtained using the previously seen evaluating functions) is recorded for each fold iteration and then finally averaged in **average_accuracy**.  \n",
    "The implementation also provides additional information about the time elapsed and the fold or training iteration frequency in the computation: these information can be displayed or not by acting on the **verbose** and **verbose_train** flags (respectively regarding information for the cross-validation process and the specific training iterations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(rdd, folds=10, iterations=None,\n",
    "                     learning_rate=None, lambda_reg=None,\n",
    "                     verbose=True, verbose_train=False):\n",
    "    if verbose:\n",
    "        start_time = time.time()\n",
    "        \n",
    "    total_accuracy = 0\n",
    "    rdd_cv = transform_c_v(rdd, folds)\n",
    "\n",
    "    for fold in range(folds):\n",
    "        rdd_train, rdd_test = get_block_data(rdd_cv, fold)\n",
    "        \n",
    "        if verbose:\n",
    "            tot_train = rdd_train.count()\n",
    "            tot_test = rdd_test.count()\n",
    "            perc_test = tot_test / (tot_test + tot_train) * 100\n",
    "            print('Fold %2d of %2d' % (fold + 1, folds))\n",
    "            print('Train %4d\\tTest %4d\\t|\\t%0.1f %% train' %\n",
    "                  (tot_train, tot_test, perc_test)\n",
    "            )\n",
    "        \n",
    "        b, w, loss_history = train(\n",
    "            rdd_train,\n",
    "            iterations=iterations,\n",
    "            lambda_reg=lambda_reg,\n",
    "            verbose=verbose_train\n",
    "        )\n",
    "        \n",
    "        results = evaluate(rdd_test, b, w, plot=False)\n",
    "        accuracy = results['Accuracy']\n",
    "        total_accuracy += accuracy\n",
    "        if verbose:\n",
    "            print('Accuracy: %0.4f\\n' % accuracy)\n",
    "\n",
    "    average_accuracy = total_accuracy / folds\n",
    "    if verbose:\n",
    "        total_time = time.time() - start_time\n",
    "        print('Average accuracy: %0.4f' % average_accuracy)\n",
    "        print('Total time: %0.2f s\\nFold frequency: %0.2f Hz' % \n",
    "              (total_time, (folds / total_time))\n",
    "        )\n",
    "          \n",
    "    return average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 of  2\n",
      "Train 2223\tTest 2378\t|\t51.7 % train\n",
      "It.    0\t|\tLoss: 0.6931\t|\tTime: 0.16 s\n",
      "It.    4\t|\tLoss: 0.2785\t|\tTime: 0.78 s\n",
      "It.    8\t|\tLoss: 0.2217\t|\tTime: 1.56 s\n",
      "It.   12\t|\tLoss: 0.2149\t|\tTime: 2.18 s\n",
      "It.   16\t|\tLoss: 0.2126\t|\tTime: 2.71 s\n",
      "\n",
      "Total time: 3.22 s\n",
      "Iters frequency: 6.22 Hz\n",
      "prec 0.9140\n",
      "Accuracy: 0.9222\n",
      "\n",
      "Fold  2 of  2\n",
      "Train 2378\tTest 2223\t|\t48.3 % train\n",
      "It.    0\t|\tLoss: 0.6931\t|\tTime: 0.17 s\n",
      "It.    4\t|\tLoss: 0.2584\t|\tTime: 0.74 s\n",
      "It.    8\t|\tLoss: 0.2154\t|\tTime: 1.33 s\n",
      "It.   12\t|\tLoss: 0.2064\t|\tTime: 1.84 s\n",
      "It.   16\t|\tLoss: 0.2027\t|\tTime: 2.38 s\n",
      "\n",
      "Total time: 2.77 s\n",
      "Iters frequency: 7.22 Hz\n",
      "prec 0.9268\n",
      "Accuracy: 0.9249\n",
      "\n",
      "Average accuracy: 0.9235\n",
      "Total time: 7.60 s\n",
      "Fold frequency: 0.26 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9235399128387487"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(rdd, folds=2, iterations=20, \n",
    "                 learning_rate=1, lambda_reg=0.1,\n",
    "                 verbose_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
